import feedparser
import requests
import time
import os
import re
import json
import sys
import html
from datetime import datetime, date
from dotenv import load_dotenv 

# åŠ è½½ .env (æœ¬åœ°è°ƒè¯•ç”¨)
load_dotenv()

# --- é…ç½®è¯»å– ---
def load_config():
    # è·å–å½“å‰è„šæœ¬ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿åœ¨ä»»ä½•ç›®å½•ä¸‹è¿è¡Œéƒ½èƒ½æ‰¾åˆ° config.json
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    config_path = os.path.join(project_root, 'config.json')
    
    if not os.path.exists(config_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ {config_path}")
        sys.exit(1)
        
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)

# è·å–ç¯å¢ƒå˜é‡
BOT_TOKEN = os.environ.get("TG_BOT_TOKEN") 
CHAT_ID = os.environ.get("TG_CHAT_ID")

def get_rss_url(categories):
    category_str = "+".join(categories)
    return f"http://export.arxiv.org/rss/{category_str}"

def send_telegram_message(message):
    if not BOT_TOKEN or not CHAT_ID:
        print(">> [è·³è¿‡å‘é€] (æœªé…ç½® Token æˆ– Chat ID)")
        return

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": message,
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    try:
        response = requests.post(url, json=payload)
        response.raise_for_status()
    except Exception as e:
        print(f"\n!! å‘é€å¤±è´¥: {e}")
        # ---------------- å…³é”®è°ƒè¯•ä¿¡æ¯ ----------------
        print(f"âŒ Telegram è¿”å›çš„é”™è¯¯è¯¦æƒ…: {response.text}")
        print("-" * 30)
        print(f"ğŸ“¦ æˆ‘å°è¯•å‘é€çš„å†…å®¹:\n{payload['text']}")
        print("-" * 30)
        # --------------------------------------------

import html
import re

def format_entry(entry, max_length):
    # 1. åŸºç¡€æ¸…æ´—ï¼šå»é™¤æ ‡é¢˜æ¢è¡Œ
    title = html.escape(entry.title.replace('\n', ' ').strip())
    authors = html.escape(entry.author)
    
    # 2. æ·±åº¦æ¸…æ´—æ‘˜è¦
    raw_summary = entry.summary.replace('\n', ' ')
    clean_text = re.sub(r'<[^>]+>', '', raw_summary).strip()
    
    # æ­£åˆ™æå– ID, Type, Abstract
    pattern = r'arXiv:([^\s]+)\s+Announce Type:\s+(.*?)\s+Abstract:\s+(.*)'
    match = re.search(pattern, clean_text, re.IGNORECASE)
    
    paper_type = "Unknown"
    abstract_text = clean_text
    
    if match:
        paper_type = match.group(2).strip()
        abstract_text = match.group(3).strip()
    
    # 3. [æ–°å¢] æå–åˆ†ç±»æ ‡ç­¾ (cs.GT, cs.DS ç­‰)
    # feedparser è§£æçš„ tags æ˜¯ä¸€ä¸ª list of dict: [{'term': 'cs.GT', ...}, ...]
    try:
        # è·å–æ‰€æœ‰æ ‡ç­¾çš„ term
        tags_list = [t['term'] for t in entry.tags]
        # è¿‡æ»¤æ‰å¯èƒ½çš„æ— å…³æ ‡ç­¾ï¼ˆArXiv æ¯”è¾ƒå¹²å‡€ï¼Œé€šå¸¸éƒ½æ˜¯åˆ†ç±»å·ï¼‰
        tags_str = ", ".join(tags_list)
    except (AttributeError, KeyError):
        tags_str = "Unknown"

    # 4. æˆªæ–­æ‘˜è¦
    if len(abstract_text) > max_length:
        abstract_text = abstract_text[:max_length] + "..."
    
    # 5. è½¬ä¹‰
    summary = html.escape(abstract_text)
    
    # 6. é“¾æ¥å¤„ç†
    abs_link = entry.link
    pdf_link = abs_link.replace("/abs/", "/pdf/") + ".pdf"
    
    # 7. ç”Ÿæˆæ ‡ç­¾æ ·å¼
    type_emoji = "ğŸ†•" if "new" in paper_type.lower() else "ğŸ”„"
    type_label = f"<code>[{paper_type.upper()}]</code>"
    tags_label = f"ğŸ· <code>{tags_str}</code>" # [æ–°å¢] åˆ†ç±»æ ‡ç­¾æ ·å¼
    
    # 8. æ„å»ºæ¶ˆæ¯
    msg = (
        f"<b>ğŸ“„ {title}</b>\n"
        f"{type_emoji} {type_label} | {tags_label}\n\n"  # [ä¿®æ”¹] æŠŠåˆ†ç±»åŠ åœ¨è¿™ä¸€è¡Œ
        f"<b>ğŸ‘¥ Authors:</b> {authors}\n\n"
        f"<b>ğŸ“ Abstract:</b>\n{summary}\n\n"
        f"ğŸ”— <a href='{pdf_link}'>PDF Download</a> | <a href='{abs_link}'>Abs Page</a>"
    )
    return msg

def is_today(entry_date_struct):
    """åˆ¤æ–­æ–‡ç« æ—¥æœŸæ˜¯å¦æ˜¯ä»Šå¤© (UTC)"""
    # feedparser è§£æçš„æ—¶é—´æ˜¯ time.struct_time
    # æˆ‘ä»¬å°†å…¶è½¬æ¢ä¸º date å¯¹è±¡
    entry_date = date(entry_date_struct.tm_year, entry_date_struct.tm_mon, entry_date_struct.tm_mday)
    today = datetime.utcnow().date()
    return entry_date == today

def main():
    # 1. åŠ è½½é…ç½®
    config = load_config()
    categories = config.get("categories", [])
    # è·å– max_itemsï¼Œå¦‚æœæ²¡å†™åˆ™é»˜è®¤ä¸º 0
    max_items = config.get("max_items", 0)
    summary_length = config.get("summary_length", 800)
    
    if not categories:
        print("é”™è¯¯: é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰ categories")
        sys.exit(1)

    # 2. è·å– RSS
    rss_url = get_rss_url(categories)
    print(f"æ­£åœ¨è·å– RSS: {rss_url}")
    
    feed = feedparser.parse(rss_url)
    total_entries = len(feed.entries)
    print(f"è·å–åˆ° {total_entries} ç¯‡æ–‡ç« ")
    
    if total_entries == 0:
        print("æ²¡æœ‰æ–°æ–‡ç« ã€‚")
        return

    # 3. éå†å¹¶å‘é€
    print(f"é™åˆ¶æ•°é‡: {'æ— é™åˆ¶' if max_items == 0 else max_items}")

    print(f"å½“å‰ UTC æ—¥æœŸ: {datetime.utcnow().date()}")

    count = 0
    for entry in feed.entries:
        # 1. æ£€æŸ¥æ•°é‡é™åˆ¶
        if max_items > 0 and count >= max_items:
            break
            
        # 2. [æ–°å¢] æ£€æŸ¥æ—¥æœŸï¼šå¦‚æœä¸æ˜¯ä»Šå¤©å‘å¸ƒçš„ï¼Œå°±è·³è¿‡
        # æ³¨æ„ï¼šArXiv çš„ RSS é‡Œ published_parsed æ˜¯ UTC æ—¶é—´
        if not is_today(entry.published_parsed):
            print(f"è·³è¿‡æ—§æ–‡ç« : {entry.title[:20]}... ({entry.published[:10]})")
            continue

        print(f"[{count+1}] æ­£åœ¨å‘é€: {entry.title[:30]}...")
        msg = format_entry(entry, summary_length)
        send_telegram_message(msg)
        count += 1
        time.sleep(1) 

    if count == 0:
        print("ä»Šå¤©æ²¡æœ‰æ–°æ–‡ç«  (å¯èƒ½æ˜¯å‘¨æœ«æˆ– ArXiv å°šæœªæ›´æ–°)ã€‚")
    else:
        print(f"ä»»åŠ¡å®Œæˆï¼Œå…±æ¨é€ {count} ç¯‡")

if __name__ == "__main__":
    main()